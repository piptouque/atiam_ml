{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Machine Learning - Sampling\n",
    "\n",
    "### Author: Philippe Esling (esling@ircam.fr)\n",
    "\n",
    "In this course we will cover\n",
    "1. Defining [sampling](#sampling) procedure with Monte-Carlo.\n",
    "2. Motivating the use of [Markov chains](#markov) in sampling.\n",
    "2. Implementing the [Gibbs sampling](#gibbs) algorithm.\n",
    "\n",
    "We begin with the standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from helper_plot import hdr_plot_style\n",
    "hdr_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sampling\"></a>\n",
    "## Sampling\n",
    "\n",
    "The main idea of sampling, is that we have a very complicated distribution, for which we do not know either the closed-form or its parameters. Although it is hard to find an adequate estimation of this distribution, we can try to solve simpler problems, by estimating _expected values_ of this distribution. To do so, we will define an _estimator_, for which we know that it will provide an accurate evaluation if we have a sufficient number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Example with $\\pi$\n",
    "\n",
    "A simple example to understand the underlying logic is that of trying to approximate $\\pi$. We know that we have the following relations, which means that we can estimate $\\pi$ as a form of expectation, by drawing _random samples_\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\pi}{4} &= \\mathbb{E}\\left[ x^{2} + y^{2} \\leq 1 \\right] \\\\\n",
    "&\\approx \\frac{1}{M} \\sum_{s=1}^{M} \\left[ x_{s}^{2} + y_{s}^{2} \\leq 1 \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "with $x_{s},y_{s}\\sim \\mathcal{U}(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "import math as m\n",
    "# Number of darts that land inside.\n",
    "inside = 0\n",
    "inside_pts = []\n",
    "outside_pts = []\n",
    "# Total number of darts to throw.\n",
    "total = 10000\n",
    "# Iterate for the number of darts.\n",
    "for i in range(0, total):\n",
    "    # Generate random x, y in [0, 1].\n",
    "    x2 = r.random() ** 2\n",
    "    y2 = r.random() ** 2\n",
    "    # Increment if inside unit circle.\n",
    "    if (x2 + y2) <= 1.0:\n",
    "        inside += 1\n",
    "        inside_pts.append([m.sqrt(x2), m.sqrt(y2)])\n",
    "    else:\n",
    "        outside_pts.append([m.sqrt(x2), m.sqrt(y2)])\n",
    "# Compute estimator\n",
    "pi = (float(inside) / total) * 4\n",
    "print(pi)\n",
    "# Plot the points\n",
    "inside_pts = np.array(inside_pts)\n",
    "outside_pts = np.array(outside_pts)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(inside_pts[:, 0], inside_pts[:, 1], s=10)\n",
    "plt.scatter(outside_pts[:, 0], outside_pts[:, 1], s=10, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of Monte-Carlo\n",
    "- Very simple to program\n",
    "- Universally applicable to lots of problems\n",
    "- Scalable to parallelization\n",
    "\n",
    "Problems \n",
    "- Usually very slow\n",
    "- Better solutions might exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal introduction\n",
    "\n",
    "The goal of Monte-Carlo methods is to _estimate expected values by sampling_\n",
    "So we can define\n",
    "$$\n",
    "\\mathbb{E}_{p(x)} f(x) \\approx \\frac{1}{M} \\sum_{s=1}^{M} f(x_{s})\n",
    "$$\n",
    "with $x_{s} \\sim p(x)$. This has nice co-properties\n",
    "- This is an _unbiased_ estimator\n",
    "- Guarantees on the convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why estimate expected values ?\n",
    "\n",
    "Remember the goal of full Bayesian inference\n",
    "$$\n",
    "\\begin{align}\n",
    "p(y \\vert x, Y_{train}, X_{train}) &= \\int p(y \\vert x, w) p(w \\vert y_{train}, x_{train}) dw \\\\\n",
    "&= \\mathbb{E}_{p(w\\vert Y_{train},X_{train})} p(y \\vert x, w)\n",
    "\\end{align}\n",
    "$$\n",
    "Here we can use sample to simplify the problem by _sampling_\n",
    "\n",
    "The same situation applies for the M-step of the EM-algorithm\n",
    "$$\n",
    "\\underset{\\theta}{\\max} \\mathbb{E}_{q} \\log p(\\mathbf{x},\\mathbf{t} \\vert \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from 1d distributions\n",
    "\n",
    "We start from the simplest case, where we have a discrete 1-d distribution. Imagine we want to sample from a Gaussian, so we can use the central limit theorem\n",
    "$$\n",
    "z = \\sum_{i=1}^{12} x_{i} - 6\n",
    "$$\n",
    "If we take $x_{i} \\sim \\mathcal{U}[0,1]$, then we have $p(z)\\approx\\mathcal{N}(0,1)$.\n",
    "Of course this is a rather crude approximation, we can rather use a more refined process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine we have a more complex distribution like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.stats as stats\n",
    "x = np.linspace(-7, 8, 100)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x, stats.norm.pdf(x, -1, 1.1) + stats.norm.pdf(x, 2, 0.9), linewidth = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can upper-bound our distribution by an approximation, for instance we have that\n",
    "$$\n",
    "\\begin{align}\n",
    "q(x) &= \\mathcal{N}(1,3) \\\\\n",
    "p(x) &\\leq 2q(x)\n",
    "\\end{align}\n",
    "$$\n",
    "We use the constant $2$ as it is impossible to upper bound a distribution without multiplying it with a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.stats as stats\n",
    "x = np.linspace(-7, 8, 100)\n",
    "plt.plot(x, 0.5 * stats.norm.pdf(x, -1, 1.1) + 0.5 * stats.norm.pdf(x, 2, 0.9), linewidth=3)\n",
    "plt.plot(x, stats.norm.pdf(x, 1, 3) * 2, c='r', linewidth=3)\n",
    "plt.savefig('sampling_approx.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now note that we can sample from this approximation $q$ such that $\\tilde{x}\\sim q(x)$\n",
    "- So how can we sample from our distribution $p$\n",
    "- We now that we have a higher probability in $q$\n",
    "- Therefore we need to *reject* some of the points\n",
    "- The rule to reject should be probabilistic\n",
    "    - Should be proportional to the height of the curves\n",
    "    - So if we sample $\\tilde{x}$ and take its coordinates $y \\sim \\mathcal{U}[0, 2q(\\tilde{x})]$.\n",
    "    - We can accept $\\tilde{x}$ with probability $\\frac{p(x)}{2q(x)}$ if $y\\leq p(x)$\n",
    "How much points do we accept ? Knowing that we have $p(x)\\leq Mq(x)$, we accept $\\frac{1}{M}$ points on average\n",
    "\n",
    "Note that we can even use this _rejection sampling_ method if we know the distribution up to a normalization factor as\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\hat{p}(x)}{Z} &\\leq Mq(x) \\\\\n",
    "\\hat{p}(x) &\\leq ZMq(x) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "For instance, we can define our distributions $p$ and $q$ as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "def p(x):\n",
    "    return st.norm.pdf(x, loc=30, scale=10) + st.norm.pdf(x, loc=80, scale=20)\n",
    "def q(x):\n",
    "    return st.norm.pdf(x, loc=50, scale=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can implement the algorithm for rejection sampling and test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-50, 151)\n",
    "k = max(p(x) / q(x))\n",
    "\n",
    "def rejection_sampling(iter=1000):\n",
    "    samples = []\n",
    "    \n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "plt.plot(x, p(x))\n",
    "plt.plot(x, k*q(x))\n",
    "plt.show()\n",
    "s = rejection_sampling(iter=10000)\n",
    "sns.distplot(s);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of rejection sampling\n",
    "+ Pro : Works for most distributions\n",
    "- Con : If $q$ and $p$ too different ($M$ large), rejects most points\n",
    "- Con : $M$ is large for d-dimensional distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"markov\"></a>\n",
    "## Markov chains\n",
    "\n",
    "**Here explain the principle of Markov chains**\n",
    "\n",
    "Using Markov chain for sampling\n",
    "- We want to sample from p(x)\n",
    "- Build a Markov chain that converges to $p(x)$\n",
    "- Start from any $x^{0}$\n",
    "- For $k=0,1,\\cdots$\n",
    "$$\n",
    "x^{k+1}\\sim T(x^{k}\\rightarrow x^{k+1})\n",
    "$$\n",
    "- Eventually $x^{k}$ will look like samples from p(x)\n",
    "\n",
    "### Do chains always converge ?\n",
    "\n",
    "- Imagine a binary distribution\n",
    "- Will never converge\n",
    "- We need chains that do converge\n",
    "\n",
    "**Definition** : A distribution $\\pi$ is called _stationary_ if\n",
    "$$\n",
    "\\pi(x')=\\sum_{x} T(x\\rightarrow x') \\pi(x)\n",
    "$$\n",
    "\n",
    "**Theorem** : If $T(x\\rightarrow x') > 0$ for all $x, x'$, then there exists a unique $\\pi$ such that\n",
    "$$\n",
    "\\pi(x')=\\sum_{x} T(x\\rightarrow x') \\pi(x)\n",
    "$$\n",
    "And the Markov chain converges to $\\pi$ from any starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs sampling\n",
    "\n",
    "One of the easiest method to construct Markov chains to sample from a distribution. Say we have a 3-d distribution that we know up to norrmalization.\n",
    "$$\n",
    "p(x_{1}, x_{2}, x_{3}) = \\frac{\\hat{p}(x_{1}, x_{2}, x_{3})}{Z}\n",
    "$$\n",
    "The method of Gibbs sampling starts with $(x^{0}_{1}, x^{0}_{2}, x^{0}_{3})$ that we can set to $(0,0,0)$ for instance.\n",
    "\n",
    "Then we are going to sample each dimension at a time by sampling from the conditional\n",
    "$$\n",
    "\\begin{align}\n",
    "x^{1}_{1} \\sim &p(x_{1} \\vert x_{2} = x^{0}_{2}, x_{3} = x^{0}_{3}) \\\\\n",
    "&= \\frac{\\hat{p}(x_{1}, x^{0}_{2}, x^{0}_{3})}{Z}\n",
    "\\end{align}\n",
    "$$\n",
    "Then we reapply the same idea for the next dimensions.\n",
    "$$\n",
    "\\begin{align}\n",
    "x^{1}_{2} &\\sim p(x_{2} \\vert x_{1} = x^{1}_{1}, x_{3} = x^{0}_{3}) \\\\\n",
    "x^{1}_{3} &\\sim p(x_{3} \\vert x_{1} = x^{1}_{1}, x_{2} = x^{1}_{2}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Note that in this case, we cannot parallelize these sampling steps.\n",
    "\n",
    "We can prove that Gibbs sampling indeed converges to the desired distribution $p$. So we want to prove\n",
    "$$\n",
    "p(x',y',z') = \\sum_{x,y,z} q(x,y,z\\rightarrow x',y',z') p(x,y,z)\n",
    "$$\n",
    "\n",
    "Pros :\n",
    "- Reduce multidimensional sampling to sequence of 1d sampling\n",
    "- A few lines of code\n",
    "Cons :\n",
    "- Highly correlated samples\n",
    "- Slow convergence (mixing)\n",
    "- Cannot be parallelized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings\n",
    "\n",
    "- Sometimes Gibbs samples are too correlated\n",
    "- Idea of MH is to apply rejection sampling to Markov chains\n",
    "Let's start with any Markov chain $Q$ \n",
    "- Sample $x'$ from a _wrong_ $Q(x^{k}\\rightarrow x')$ for $k=1,2,\\cdots$\n",
    "- Use a critic to accept proposal $x'$ with probabiility $A(x^{k}\\rightarrow x')$\n",
    "- Otherwise stay at $x^{k}$, such that $x^{k+1}=x^{k}$\n",
    "So overall, the scheme works as\n",
    "$$\n",
    "\\begin{align}\n",
    "T(x\\leftarrow x') &= Q(x\\leftarrow x')A(x\\leftarrow x'), \\forall x\\neq x'\n",
    "T(x\\leftarrow x) &= Q(x\\leftarrow x)A(x\\leftarrow x)\\\\\n",
    "&+ \\sum_{x\\neq x'} Q(x\\leftarrow x')(1 - A(x\\leftarrow x'))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "How to choose A : $\\pi(x')=\\sum_{x} T(x\\rightarrow x') \\pi(x)$, we need to introduce the _detailed balance_ condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gibbs\"></a>\n",
    "## [Bonus] Gibbs Sampling implementation\n",
    "\n",
    "The Gibbs sampler is the simplest and most prevalent MCMC algorithm. If a posterior has $k$ parameters to be estimated, we may condition each parameter on current values of the other $k-1$ parameters, and sample from the resultant distributional form (usually easier), and repeat this operation on the other parameters in turn. This procedure generates samples from the posterior distribution. Note that we have now combined Markov chains (conditional independence) and Monte Carlo techniques (estimation by simulation) to yield Markov chain Monte Carlo.\n",
    "\n",
    "Here is a stereotypical Gibbs sampling algorithm:\n",
    "\n",
    "1.  Choose starting values for states (parameters):\n",
    "    ${\\bf \\theta} = [\\theta_1^{(0)},\\theta_2^{(0)},\\ldots,\\theta_k^{(0)}]$.\n",
    "\n",
    "2.  Initialize counter $j=1$.\n",
    "\n",
    "3.  Draw the following values from each of the $k$ conditional\n",
    "    distributions:\n",
    "\n",
    "    $$\\begin{aligned}\n",
    "    \\theta_1^{(j)} &\\sim \\pi(\\theta_1 | \\theta_2^{(j-1)},\\theta_3^{(j-1)},\\ldots,\\theta_{k-1}^{(j-1)},\\theta_k^{(j-1)}) \\\\\n",
    "    \\theta_2^{(j)} &\\sim \\pi(\\theta_2 | \\theta_1^{(j)},\\theta_3^{(j-1)},\\ldots,\\theta_{k-1}^{(j-1)},\\theta_k^{(j-1)}) \\\\\n",
    "    \\theta_3^{(j)} &\\sim \\pi(\\theta_3 | \\theta_1^{(j)},\\theta_2^{(j)},\\ldots,\\theta_{k-1}^{(j-1)},\\theta_k^{(j-1)}) \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_{k-1}^{(j)} &\\sim \\pi(\\theta_{k-1} | \\theta_1^{(j)},\\theta_2^{(j)},\\ldots,\\theta_{k-2}^{(j)},\\theta_k^{(j-1)}) \\\\\n",
    "    \\theta_k^{(j)} &\\sim \\pi(\\theta_k | \\theta_1^{(j)},\\theta_2^{(j)},\\theta_4^{(j)},\\ldots,\\theta_{k-2}^{(j)},\\theta_{k-1}^{(j)})\\end{aligned}$$\n",
    "\n",
    "4.  Increment $j$ and repeat until convergence occurs.\n",
    "\n",
    "As we can see from the algorithm, each distribution is conditioned on the last iteration of its chain values, constituting a Markov chain as advertised. The Gibbs sampler has all of the important properties outlined in the previous section: it is aperiodic, homogeneous and ergodic. Once the sampler converges, all subsequent samples are from the target distribution. This convergence occurs at a geometric rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Inferring patterns in UK coal mining disasters\n",
    "\n",
    "Let's try to model a more interesting example, a time series of recorded coal mining \n",
    "disasters in the UK from 1851 to 1962.\n",
    "\n",
    "Occurrences of disasters in the time series is thought to be derived from a \n",
    "Poisson process with a large rate parameter in the early part of the time \n",
    "series, and from one with a smaller rate in the later part. We are interested \n",
    "in locating the change point in the series, which perhaps is related to changes \n",
    "in mining safety regulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disasters_array = np.array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n",
    "                            3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n",
    "                            2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,\n",
    "                            1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n",
    "                            0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n",
    "                            3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n",
    "                            0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n",
    "\n",
    "n_count_data = len(disasters_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Poisson random variables for this type of count data. Denoting year $i$'s accident count by $y_i$, \n",
    "\n",
    "$$y_i \\sim \\text{Poisson}(\\lambda).$$\n",
    "\n",
    "For those unfamiliar, Poisson random variables look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for l in [1, 5, 12, 25]:\n",
    "    plt.hist(np.random.poisson(l, 1000), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modeling problem is about estimating the values of the $\\lambda$ parameters. Looking at the time series above, it appears that the rate declines over time.\n",
    "\n",
    "A **changepoint model** identifies a point (here, a year) after which the parameter $\\lambda$ drops to a lower value. Let us call this point in time $\\tau$. So we are estimating two $\\lambda$ parameters:\n",
    "$\\lambda = \\lambda_1$ if $t \\lt \\tau$ and $\\lambda = \\lambda_2$ if $t \\geq \\tau$.\n",
    "\n",
    "We need to assign prior probabilities to both $\\{\\lambda_1, \\lambda_2\\}$. The gamma distribution not only provides a continuous density function for positive numbers, but it is also *conjugate* with the Poisson sampling distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1_lambda2 = [(0.1, 100), (1, 100), (1, 10), (10, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for p in lambda1_lambda2:\n",
    "    plt.hist(np.random.gamma(*p, size=1000), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will specify suitably vague hyperparameters $\\alpha$ and $\\beta$ for both priors:\n",
    "\n",
    "\\begin{align}\n",
    "\\lambda_1 &\\sim \\text{Gamma}(1, 10), \\\\\n",
    "\\lambda_2 &\\sim \\text{Gamma}(1, 10).\n",
    "\\end{align}\n",
    "\n",
    "Since we do not have any intuition about the location of the changepoint (unless we visualize the data), we will assign a discrete uniform prior over the entire observation period [1851, 1962]:\n",
    "\n",
    "\\begin{align}\n",
    "&\\tau \\sim \\text{DiscreteUniform(1851, 1962)}\\\\\n",
    "&\\Rightarrow P(\\tau = k) = \\frac{1}{111}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Gibbs sampling\n",
    "\n",
    "We are interested in estimating the joint posterior of $\\lambda_1, \\lambda_2$ and $\\tau$ given the array of annnual disaster counts $\\mathbf{y}$. This gives:\n",
    "\n",
    "$$\n",
    " P( \\lambda_1, \\lambda_2, \\tau | \\mathbf{y} ) \\propto P(\\mathbf{y} | \\lambda_1, \\lambda_2, \\tau ) P(\\lambda_1, \\lambda_2, \\tau) \n",
    "$$\n",
    "\n",
    "To employ Gibbs sampling, we need to factor the joint posterior into the product of conditional expressions:\n",
    "\n",
    "$$\n",
    " P(\\lambda_1, \\lambda_2, \\tau | \\mathbf{y}) \\propto P(y_{t \\lt \\tau} | \\lambda_1, \\tau) P(y_{t \\geq \\tau} | \\lambda_2, \\tau) P(\\lambda_1) P(\\lambda_2) P(\\tau)\n",
    "$$\n",
    "\n",
    "which we have specified as:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "P( \\lambda_1, \\lambda_2, \\tau | \\mathbf{y} ) &\\propto \\left[\\prod_{t=1851}^{\\tau} \\text{Poi}(y_t|\\lambda_1) \\prod_{t=\\tau+1}^{1962} \\text{Poi}(y_t|\\lambda_2) \\right] \\text{Gamma}(\\lambda_1|\\alpha,\\beta) \\text{Gamma}(\\lambda_2|\\alpha, \\beta) \\frac{1}{111} \\\\\n",
    "&\\propto \\left[\\prod_{t=1851}^{\\tau} e^{-\\lambda_1}\\lambda_1^{y_t} \\prod_{t=\\tau+1}^{1962} e^{-\\lambda_2} \\lambda_2^{y_t} \\right] \\lambda_1^{\\alpha-1} e^{-\\beta\\lambda_1} \\lambda_2^{\\alpha-1} e^{-\\beta\\lambda_2} \\\\\n",
    "&\\propto \\lambda_1^{\\sum_{t=1851}^{\\tau} y_t +\\alpha-1} e^{-(\\beta+\\tau)\\lambda_1} \\lambda_2^{\\sum_{t=\\tau+1}^{1962} y_i + \\alpha-1} e^{-\\beta\\lambda_2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "So, the full conditionals are known, and critically for Gibbs, can easily be sampled from.\n",
    "\n",
    "$$\\lambda_1 \\sim \\text{Gamma}(\\sum_{t=1851}^{\\tau} y_t +\\alpha, \\tau+\\beta)$$\n",
    "$$\\lambda_2 \\sim \\text{Gamma}(\\sum_{t=\\tau+1}^{1962} y_i + \\alpha, 1962-\\tau+\\beta)$$\n",
    "$$\\tau \\sim \\text{Categorical}\\left( \\frac{\\lambda_1^{\\sum_{t=1851}^{\\tau} y_t +\\alpha-1} e^{-(\\beta+\\tau)\\lambda_1} \\lambda_2^{\\sum_{t=\\tau+1}^{1962} y_i + \\alpha-1} e^{-\\beta\\lambda_2}}{\\sum_{k=1851}^{1962} \\lambda_1^{\\sum_{t=1851}^{\\tau} y_t +\\alpha-1} e^{-(\\beta+\\tau)\\lambda_1} \\lambda_2^{\\sum_{t=\\tau+1}^{1962} y_i + \\alpha-1} e^{-\\beta\\lambda_2}} \\right)$$\n",
    "\n",
    "Implementing this in Python requires random number generators for both the gamma and discrete uniform distributions. We can leverage NumPy for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw random gamma variate\n",
    "rgamma = np.random.gamma\n",
    "\n",
    "def rcategorical(probs, n=None):\n",
    "    # Function to draw random categorical variate\n",
    "    return np.array(probs).cumsum().searchsorted(np.random.sample(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in order to generate probabilities for the conditional posterior of $\\tau$, we need the kernel of the gamma density:\n",
    "\n",
    "\\\\[\\lambda^{\\alpha-1} e^{-\\beta \\lambda}\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgamma = lambda lam, a, b: lam**(a - 1) * np.exp(-b * lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffuse hyperpriors for the gamma priors on $\\{\\lambda_1, \\lambda_2\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = 1., 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computational efficiency, it is best to pre-allocate memory to store the sampled values. We need 3 arrays, each with length equal to the number of iterations we plan to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of iterations\n",
    "n_iterations = 1000\n",
    "# Initialize trace of samples\n",
    "lambda1, lambda2, tau = np.empty((3, n_iterations + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The penultimate step initializes the model paramters to arbitrary values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1[0] = 6\n",
    "lambda2[0] = 2\n",
    "tau[0] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the Gibbs sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from conditionals\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    ######################\n",
    "    # YOUR CODE GOES HERE\n",
    "    ######################\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the trace and histogram of the samples reveals the marginal posteriors of each parameter in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lambda1)\n",
    "plt.figure()\n",
    "plt.hist(lambda1)\n",
    "plt.figure()\n",
    "plt.plot(lambda2)\n",
    "plt.figure()\n",
    "plt.hist(lambda2)\n",
    "plt.figure()\n",
    "plt.plot(tau)\n",
    "plt.figure()\n",
    "plt.hist(tau)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
